## Hướng dẫn thực hiện chuyển l3 agent và dhcp sang compute

Thực hiện di chuyển l3 agent và dhcp agent từ controller sang con compute để:

* Bỏ hai đường data-vm và provider trên con controller 
* Các vm sefl-service sẽ không cần lên controller giao tiếp với nhau hoặc đi ra ngoài mạng nữa
* Việc cấp dhcp được thực hiện trên compute

**MỤC LỤC**

[1. Trên controller](#ctl)

[2. Trên compute](#com)

[3. Tạo network](#create_net)

[4. Cấu hình HA L3 agent](#ha_l3)

[5. Cấu hình native OVS firewall driver](#ovs-firewall)

[6. Cấu hình HA DHCP](#ha_dhcp)

[Tham khảo](#ref)


<a name="ctl"></a>
## 1. Thực hiện trên controller

* Đầu tiên cần xóa hết toàn bộ network, subnet, port, router, instance, namespace cũ đi

* Tắt card mạng tạm thời 

	```sh
	ifdown br-provider
	ifdown eth1
	ifdown eth2
	```
* Để tắt hẳn luôn, thay đổi option `ONBOOT=yes` sửa thành `ONBOOT=no` trong file cấu hình của 3 card mạng trên sau đó khởi động lại network (hoặc có thể gỡ bỏ)

	```sh
	vim /etc/sysconfig/network-scripts/ifcfg-eth1
	vim /etc/sysconfig/network-scripts/ifcfg-eth2
	vim /etc/sysconfig/network-scripts/ifcfg-br-provider
	systemctl restart network
	```

* Dừng các dịch vụ sau:

	```sh
	systemctl stop openvswitch
	systemctl stop neutron-openvswitch-agent.service
	systemctl stop neutron-dhcp-agent.service
	systemctl stop neutron-metadata-agent.service
	systemctl stop neutron-l3-agent
	systemctl disable neutron-openvswitch-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service neutron-l3-agent
	```
	Hoặc gỡ bỏ luôn:

	```sh
	yum remove -y openvswitch openstack-neutron-ml2 openstack-neutron-openvswitch
	```

Trên controller lúc này chỉ còn cài đặt layer 2.

<a name="com"></a>
## 2. Trên compute

* Cài thêm các gói

		yum --enablerepo=centos-openstack-rocky,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch ebtables

* Sửa file `/etc/neutron/neutron.conf`

	```sh
	[root@trang-40-72 ~(openstack)]# cat /etc/neutron/neutron.conf | egrep -v "^#|^$"
	[DEFAULT]
	auth_strategy = keystone
	core_plugin = ml2
	transport_url = rabbit://openstack:trang1234@192.168.40.71
	auth_strategy = keystone
	service_plugins = router
	allow_overlapping_ips = True
	notify_nova_on_port_status_changes = True
	notify_nova_on_port_data_changes = True
	[agent]
	[cors]
	[database]
	connection = mysql+pymysql://neutron:trang1234@192.168.40.71/neutron
	[keystone_authtoken]
	www_authenticate_uri = http://192.168.40.71:5000
	auth_url = http://192.168.40.71:5000
	memcached_servers = 192.168.40.71:11211
	auth_type = password
	project_domain_name = default
	user_domain_name = default
	project_name = service
	username = neutron
	password = trang1234
	[matchmaker_redis]
	[nova]
	auth_url = http://192.168.40.71:5000
	auth_type = password
	project_domain_name = Default
	user_domain_name = Default
	region_name = RegionOne
	project_name = service
	username = nova
	password = trang1234
	[oslo_concurrency]
	lock_path = /var/lib/neutron/tmp
	```
	
* File `/etc/neutron/plugins/ml2/ml2_conf.ini`

	```sh
	[root@trang-40-72 ~(openstack)]# cat /etc/neutron/plugins/ml2/ml2_conf.ini | egrep -v "^#|^$"
	[ml2]
	type_drivers = flat,vlan,vxlan
	tenant_network_types = vxlan
	mechanism_drivers = openvswitch,l2population
	extension_drivers = port_security
	[ml2_type_flat]
	flat_networks = provider
	[ml2_type_vlan]
	network_vlan_ranges = provider
	[ml2_type_vxlan]
	vni_ranges = 1:1000
	[securitygroup]
	firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
	enable_ipset = True
	```

* File `/etc/neutron/plugins/ml2/openvswitch_agent.ini`

	```sh
	[root@trang-40-72 ~(openstack)]# cat /etc/neutron/plugins/ml2/openvswitch_agent.ini | egrep -v "^#|^$"
	[DEFAULT]
	[agent]
	tunnel_types = vxlan
	l2_population = True
	[network_log]
	[ovs]
	bridge_mappings = provider:br-provider
	local_ip = 192.168.50.72
	[securitygroup]
	enable_security_group = True
	firewall_driver = iptables_hybrid
	[xenapi]
	```

* File `/etc/neutron/dhcp_agent.ini`

	```sh
	[root@trang-40-72 ~(openstack)]# cat /etc/neutron/dhcp_agent.ini | egrep -v "^#|^$"
	[DEFAULT]
	interface_driver = openvswitch
	dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
	enable_isolated_metadata = True
	force_metadata = True
	[agent]
	[ovs]
	```

* File `/etc/neutron/metadata_agent.ini`

	```sh
	[root@trang-40-72 ~(openstack)]# cat /etc/neutron/metadata_agent.ini | egrep -v "^#|^$"
	[DEFAULT]
	nova_metadata_ip = 192.168.40.71
	metadata_proxy_shared_secret = trang1234
	[agent]
	[cache]
	```

* File `/etc/neutron/l3_agent.ini`

	```sh
	[root@trang-40-72 ~(openstack)]# cat /etc/neutron/l3_agent.ini`
	 | egrep -v "^#|^$"
	[DEFAULT]
	interface_driver = openvswitch
	external_network_bridge =
	[agent]
	[ovs]
	```

* Cấu hình Nova sử dụng networking service: Chỉnh sửa trong file `/etc/nova/nova.conf`

	```sh
	[neutron]
	url = http://192.168.40.71:9696
	auth_url = http://192.168.40.71:5000
	auth_type = password
	project_domain_name = Default
	user_domain_name = Default
	region_name = RegionOne
	project_name = service
	username = neutron
	password = trang1234
	```

* Khởi động lại các dịch vụ và đồng bộ Database:

	```sh
	systemctl restart network
	ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
	su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron
	```

* Bật các dịch vụ:

	```sh
	systemctl enable neutron-server.service neutron-openvswitch-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service
	systemctl start neutron-server.service neutron-openvswitch-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service
	systemctl enable neutron-l3-agent.service
	systemctl start neutron-l3-agent.service
	```

* Trên controller thực hiện

		systemctl restart openstack-nova-api.service

> Lưu ý: có thể sẽ phải khởi động lại các node compute

<a name="create_net"></a>
## 3. Tạo network

```sh
#
# Create provider network
#
openstack network create  --share --external --provider-physical-network provider --provider-network-type flat provider
openstack subnet create --network provider \
  --allocation-pool start=192.168.68.81,end=192.168.68.100 \
  --dns-nameserver 8.8.8.8 --gateway 192.168.68.1 \
  --subnet-range 192.168.68.0/24 provider

#
# Create selfserivce network
#
openstack network create selfservice
openstack subnet create --network selfservice --dns-nameserver 8.8.8.8 --gateway 10.10.10.1 --subnet-range 10.10.10.0/24 selfservice


#
# Create router
#
openstack router create router
neutron router-interface-add router selfservice
neutron router-gateway-set router provider
```

* Kiểm tra lại trên compute được cài đặt l3 agent

	```sh
	[root@trang-40-72 ~(openstack)]# ip netns
	qrouter-665ebfbd-9b38-42af-a83d-f8fd14117df0 (id: 2)
	qdhcp-c0f0df4d-09a2-4b70-b875-71e537d9f9c6 (id: 1)
	qdhcp-ff35bec5-60f8-48e3-b55b-37989952007d (id: 0)
	```

* Trên controller
	
	```sh
	[root@trang-40-71 ~(openstack)]# openstack network agent list
	+--------------------------------------+--------------------+-------------+-------------------+-------+-------+---------------------------+
	| ID                                   | Agent Type         | Host        | Availability Zone | Alive | State | Binary                    |
	+--------------------------------------+--------------------+-------------+-------------------+-------+-------+---------------------------+
	| 1d004a35-5866-4e91-9459-c6d7e747ec52 | Metadata agent     | trang-40-72 | None              | :-)   | UP    | neutron-metadata-agent    |
	| 2d094e7f-5693-4a89-a32e-db7940d40c23 | L3 agent           | trang-40-72 | nova              | :-)   | UP    | neutron-l3-agent          |
	| 4272d1e7-6467-4e8c-becd-8d53f4ad322f | Open vSwitch agent | trang-40-72 | None              | :-)   | UP    | neutron-openvswitch-agent |
	| 74a686d2-3af7-4dce-87af-ced3fea1d568 | DHCP agent         | trang-40-72 | nova              | :-)   | UP    | neutron-dhcp-agent        |
	| b99b1a40-cced-4e2f-ba98-22cbcada24a6 | Open vSwitch agent | trang-40-73 | None              | :-)   | UP    | neutron-openvswitch-agent |
	+--------------------------------------+--------------------+-------------+-------------------+-------+-------+---------------------------+
	```	

<a name="ha_l3"></a>
## 4. Cấu hình HA cho L3 agent

### Trên controller (đã cấu hình như trên)

* Cấu hình enable VRRP trong file `/etc/neutron/neutron.conf`:
	```
	[DEFAULT]
	l3_ha = true
	max_l3_agents_per_router = 3
	```

* Trong đó: tùy chọn `max_l3_agents_per_router` là số lượng tối router ha được tạo ra. Ví dụ trên đây đang để là `3` thì khi tạo một router bất kỳ với lệnh `openstack router create` sẽ cùng lúc tạo thêm tối đa **hai** router khác trên hai l3-agent khác. Nếu chỉ có hai l3-agent thì số lượng router tạo ra cùng lúc sẽ chỉ là hai trên hai agent.

* Ví dụ tùy chọn `max_l3_agents_per_router` được cấu hình là `2` trong khi số lượng l3-agent là `3` thì neutron sẽ thực hiện lựa chọn hai trong ba agent để tạo router.

* Khởi động lại các agent:

	```sh
	systemctl restart neutron-server.service
	```


### Trên con compute 1

* Không cấu hình gì thêm

### Trên compute 2 (đã cấu hình neutron-openvswitch-agent)

* Cài đặt thêm l3-agent

	```sh
	yum --enablerepo=centos-openstack-rocky,epel -y install openstack-neutron
	```

* Chỉnh sửa file cấu hình `/etc/neutron/l3_agent.ini`:

	```sh
	[DEFAULT]
	interface_driver = openvswitch
	external_network_bridge =
	```

* Khởi động lại các agent

	```sh
	systemctl restart openvswitch neutron-openvswitch-agent neutron-openvswitch-agent
	systemctl start neutron-l3-agent.service
	systemctl enable neutron-l3-agent.service
	```

* Kiểm tra lại trên controller

	```sh
	[root@trang-40-71 ~(openstack)]# openstack network agent list
	+--------------------------------------+--------------------+-------------+-------------------+-------+-------+---------------------------+
	| ID                                   | Agent Type         | Host        | Availability Zone | Alive | State | Binary                    |
	+--------------------------------------+--------------------+-------------+-------------------+-------+-------+---------------------------+
	| 1d004a35-5866-4e91-9459-c6d7e747ec52 | Metadata agent     | trang-40-72 | None              | :-)   | UP    | neutron-metadata-agent    |
	| 2d094e7f-5693-4a89-a32e-db7940d40c23 | L3 agent           | trang-40-72 | nova              | :-)   | UP    | neutron-l3-agent          |
	| 4272d1e7-6467-4e8c-becd-8d53f4ad322f | Open vSwitch agent | trang-40-72 | None              | :-)   | UP    | neutron-openvswitch-agent |
	| 74a686d2-3af7-4dce-87af-ced3fea1d568 | DHCP agent         | trang-40-72 | nova              | :-)   | UP    | neutron-dhcp-agent        |
	| a6f87958-1f1f-4ac0-a9f9-66d6e43ff60a | L3 agent           | trang-40-73 | nova              | :-)   | UP    | neutron-l3-agent          |
	| b99b1a40-cced-4e2f-ba98-22cbcada24a6 | Open vSwitch agent | trang-40-73 | None              | :-)   | UP    | neutron-openvswitch-agent |
	+--------------------------------------+--------------------+-------------+-------------------+-------+-------+---------------------------+
	```

> Note: Nếu kiểm tra trên controller mà vẫn không thấy thì thử chạy lệnh đồng bộ database trên compute 2 <br>
> su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf  upgrade head" neutron

* Tạo thử một router:

		openstack router create router-ha

* Sau đó kiểm tra lại trên controller

	```sh
	[root@trang-40-71 ~(openstack)]# openstack router list
	+--------------------------------------+--------+--------+-------+-------------+------+----------------------------------+
	| ID                                   | Name   | Status | State | Distributed | HA   | Project                          |
	+--------------------------------------+--------+--------+-------+-------------+------+----------------------------------+
	| 42bdf304-2f05-4c9a-b981-cd134f9d26fb | router | ACTIVE | UP    | False       | True | db93189111d44af1b22d43e849de6e34 |
	+--------------------------------------+--------+--------+-------+-------------+------+----------------------------------+
	[root@trang-40-71 ~(openstack)]# openstack network list
	+--------------------------------------+----------------------------------------------------+--------------------------------------+
	| ID                                   | Name                                               | Subnets                              |
	+--------------------------------------+----------------------------------------------------+--------------------------------------+
	| 0f07d050-3d1b-4962-b90a-c7b3ee44206c | HA network tenant db93189111d44af1b22d43e849de6e34 | 18648494-9c11-424f-85d3-da0c2b413e74 |
	| 2e41a162-c2d9-499b-96d2-db74086101d4 | selfservice                                        | 96f56fdb-c243-404e-a4d9-c7d4177de888 |
	| 83d12990-2efc-4c60-8da2-c5bd59cdc8b2 | provider                                           | 6bdd45f0-b8fd-40eb-94e7-e403c69f8093 |
	+--------------------------------------+----------------------------------------------------+--------------------------------------+
	```

* Trên compute 1:
	```sh
	[root@trang-40-72 ~(openstack)]# ip netns
	qrouter-42bdf304-2f05-4c9a-b981-cd134f9d26fb (id: 2)
	qdhcp-2e41a162-c2d9-499b-96d2-db74086101d4 (id: 1)
	qdhcp-83d12990-2efc-4c60-8da2-c5bd59cdc8b2 (id: 0)
	```

* Trên compute 2:

	```sh
	[root@trang-40-73 ~(openstack)]# ip netns
	qrouter-42bdf304-2f05-4c9a-b981-cd134f9d26fb (id: 0)
	```

**Lưu ý:**

* Khi thực hiện HA layer 3 agent, thì khi tạo router sẽ có hai router được tạo ra (với mô hình ở đây là hai compute đều cài l3 agent), cùng một lúc sẽ chỉ có một con router được hoạt động

* Thực hiện cài đặt thêm một node compute nữa để kiểm tra (updating...)



<a name="ovs-firewall"></a>
## 5. Enable the native OVS firewall driver

* Trước đây, Open vSwitch (OVS) không thể tương tác trực tiếp với iptables để implement security groups. Bởi vậy, các OVS agent và Compute service sử dụng một Linux Bridge giữa các instance (VM) và OVS intergration bridge `br-int` để implement security groups. Linux bridge device bao gồm các **iptables rules** liên quan tới các instance. Nhìn chung thì các thành phần sẽ được thêm vào nằm giữa các Instance và physical network infrastructure, rất có thể gây ra nhiều vấn đề về hiệu năng và sự mở động. Để giảm bơt các vấn đề này, OVS agent sẽ có một optional firewall driver để implements security groups như các luồng trong OVS thay vì Linux Bridge và iptables, vì vậy dễ dàng mở rộng và tăng hiệu năng.


* Chỉnh sửa file `/etc/neutron/plugins/ml2/openvswitch_agent.ini` trên các node cài đặt neutron-openvswitch-agent
	
	```sh
	[securitygroup]
	firewall_driver = openvswitch
	```

* Khởi động lại agent
	```sh
	systemctl restart neutron-openvswitch-agent
	```

* Kiểm tra lại trên các node compute, ví dụ compute 1

	```sh
	[root@trang-40-72 ~(openstack)]# ip a
	1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
	    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
	    inet 127.0.0.1/8 scope host lo
	       valid_lft forever preferred_lft forever
	    inet6 ::1/128 scope host
	       valid_lft forever preferred_lft forever
	2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
	    link/ether 52:54:00:99:56:e5 brd ff:ff:ff:ff:ff:ff
	    inet 192.168.40.72/24 brd 192.168.40.255 scope global noprefixroute eth0
	       valid_lft forever preferred_lft forever
	    inet6 fe80::eb56:e750:7c10:266/64 scope link noprefixroute
	       valid_lft forever preferred_lft forever
	3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
	    link/ether 52:54:00:9b:62:f0 brd ff:ff:ff:ff:ff:ff
	    inet 192.168.50.72/24 brd 192.168.50.255 scope global noprefixroute eth1
	       valid_lft forever preferred_lft forever
	    inet6 fe80::168d:b2e2:955a:d02c/64 scope link noprefixroute
	       valid_lft forever preferred_lft forever
	4: eth2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master ovs-system state UP group default qlen 1000
	    link/ether 52:54:00:fa:7a:31 brd ff:ff:ff:ff:ff:ff
	    inet6 fe80::5054:ff:fefa:7a31/64 scope link
	       valid_lft forever preferred_lft forever
	5: ovs-system: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
	    link/ether 5a:20:eb:88:66:a9 brd ff:ff:ff:ff:ff:ff
	6: vxlan_sys_4789: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65000 qdisc noqueue master ovs-system state UNKNOWN group default qlen 1000
	    link/ether 32:fd:57:cd:b4:f7 brd ff:ff:ff:ff:ff:ff
	    inet6 fe80::30fd:57ff:fecd:b4f7/64 scope link
	       valid_lft forever preferred_lft forever
	7: br-tun: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
	    link/ether 26:2f:02:00:f8:49 brd ff:ff:ff:ff:ff:ff
	12: br-int: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
	    link/ether 4e:b1:53:5a:0b:4c brd ff:ff:ff:ff:ff:ff
	14: br-provider: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
	    link/ether 16:0b:95:1b:f4:46 brd ff:ff:ff:ff:ff:ff
	    inet 192.168.68.72/24 brd 192.168.68.255 scope global br-provider
	       valid_lft forever preferred_lft forever
	    inet6 fe80::140b:95ff:fe1b:f446/64 scope link
	       valid_lft forever preferred_lft forever
	```

<img src="../../img/4.jpg">


<a name="#ha_dhcp"></a>
## 6. Cấu hình HA DHCP

Kiểm tra ban đầu: 

```sh
[root@trang-40-72 ~(openstack)]# neutron net-list
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+----------------------------------------------------+----------------------------------+-------------------------------------------------------+
| id                                   | name                                               | tenant_id                        | subnets                                               |
+--------------------------------------+----------------------------------------------------+----------------------------------+-------------------------------------------------------+
| 591c870c-5f6b-48c7-abc4-a6cd89a83220 | selfservice                                        | db93189111d44af1b22d43e849de6e34 | ff28ff1c-f0bd-4c7d-9550-86ef811c626b 10.10.10.0/24    |
| c338f0f4-5754-4629-a02f-9fffe3d45a8e | provider                                           | db93189111d44af1b22d43e849de6e34 | 3b4dc01f-55ac-4355-9804-1de296c899f2 192.168.68.0/24  |
| e950a27a-db2a-41fc-a738-a73065a5d58a | HA network tenant db93189111d44af1b22d43e849de6e34 |                                  | 62c20abf-db2c-4a9d-9070-917df1c08f29 169.254.192.0/18 |
+--------------------------------------+----------------------------------------------------+----------------------------------+-------------------------------------------------------+
[root@trang-40-72 ~(openstack)]#  neutron dhcp-agent-list-hosting-net provider
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+-------------+----------------+-------+
| id                                   | host        | admin_state_up | alive |
+--------------------------------------+-------------+----------------+-------+
| 74a686d2-3af7-4dce-87af-ced3fea1d568 | trang-40-72 | True           | :-)   |
+--------------------------------------+-------------+----------------+-------+
```

> Chú ý: Mô hình network hiện tại đang là 1 node controller và 3 node network (cài dhcp-agent)


### Trên Controller node

Cấu hình HA DHCP mặc định neutron server trong file `/etc/neutron/neutron.conf`:

```sh
[DEFAULT]
dhcp_agents_per_network = 2
```

Khởi động lại service:

	systemctl restart neutron-server


### Trên các network node (compute node)

Chỉnh sửa file cấu hình dhcp `/etc/neutron/dhcp_agent.ini`

```sh
[DEFAULT]
interface_driver = openvswitch
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_isolated_metadata = True
force_metadata = True
```

Khởi động lại dịch vụ:

	systemctl restart neutron-dhcp-agent

### Kiểm tra kết quả

Cấu hình xong, khởi động lại dịch vụ (kiểm tra trên các node compute (dhcp agent) thấy node đã tự động tạo ra các namespace mới cho việc HA dhcp các network cũ, đã được tạo sẵn)

Tạo thêm một network mới để kiểm tra

```sh
openstack network create selfservice4
openstack subnet create --network selfservice4 --dns-nameserver 8.8.8.8 --gateway 10.10.40.1 --subnet-range 10.10.40.0/24 selfservice4
neutron router-interface-add router selfservice4
```

Khi option `dhcp_agents_per_network` được cấu hình là `2` thì hai trong 3 node agent sẽ tạo ra 2 namespace tương ứng cho network mới tạo trên. Kiểm tra xem network được tạo trên các agent nào:

```sh
[root@trang-40-71 ~(openstack)]# openstack network agent list --network selfservice4
+--------------------------------------+------------+------------------------+-------------------+-------+-------+--------------------+
| ID                                   | Agent Type | Host                   | Availability Zone | Alive | State | Binary             |
+--------------------------------------+------------+------------------------+-------------------+-------+-------+--------------------+
| 12a7f9ed-d931-42c8-ad0d-87d6576f71be | DHCP agent | trang-40-80.trang-test | nova              | :-)   | UP    | neutron-dhcp-agent |
| 3ceea5f0-8ff6-4c81-953b-f3c665176462 | DHCP agent | trang-40-73            | nova              | :-)   | UP    | neutron-dhcp-agent |
+--------------------------------------+------------+------------------------+-------------------+-------+-------+--------------------+

Hoặc:

[root@trang-40-71 ~(openstack)]# neutron dhcp-agent-list-hosting-net selfservice4
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+------------------------+----------------+-------+
| id                                   | host                   | admin_state_up | alive |
+--------------------------------------+------------------------+----------------+-------+
| 12a7f9ed-d931-42c8-ad0d-87d6576f71be | trang-40-80.trang-test | True           | :-)   |
| 3ceea5f0-8ff6-4c81-953b-f3c665176462 | trang-40-73            | True           | :-)   |
+--------------------------------------+------------------------+----------------+-------+
```

Kiểm tra các network đang có trên node agent `trang-40-73`

```sh
[root@trang-40-71 ~(openstack)]# openstack network list --agent 3ceea5f0-8ff6-4c81-953b-f3c665176462
+--------------------------------------+--------------+--------------------------------------+
| ID                                   | Name         | Subnets                              |
+--------------------------------------+--------------+--------------------------------------+
| 4edaa4f8-1f96-4a3d-be89-f846f419632a | selfservice2 | b1207250-c14d-4a8f-88ae-4714b0a24276 |
| 52142060-a9d9-4f0b-beb1-652e3b4b5086 | selfservice4 | 3278dd26-68fe-40f0-b460-ecf3cd273b2c |
| f990f8ba-6114-4fb7-8c27-37f7e78921f1 | selfservice  | 54927013-de69-4ff3-8f53-33fe64499803 |
+--------------------------------------+--------------+--------------------------------------+
```

Thực hiện tắt service `neutron-openvswitch-agent` trên host `trang-40-80.trang-test` đi, sau đó kiểm tra lại:

```sh
[root@trang-40-71 ~(openstack)]# neutron dhcp-agent-list-hosting-net selfservice4
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+-------------+----------------+-------+
| id                                   | host        | admin_state_up | alive |
+--------------------------------------+-------------+----------------+-------+
| 3ceea5f0-8ff6-4c81-953b-f3c665176462 | trang-40-73 | True           | :-)   |
| 74a686d2-3af7-4dce-87af-ced3fea1d568 | trang-40-72 | True           | :-)   |
+--------------------------------------+-------------+----------------+-------+
```

Ta có thể thấy khi một agent bị tắt, OPS sẽ tự động tạo ra các namesapce mới thay thế cho các namespace `qdhcpXXX` trên agent đó phân bố lên các agent còn lại (agent đc chọn là agent chưa có namespace của network đó). Khi bật lại service trên agent đã bị tắt, các namespace trên nó sẽ bị xóa (khi bị tắt và trong khi bị tắt thì chưa bị xóa). 

## Một số trường hợp với l3-agent & dhcp-agent

**Chú ý**: Đối với việc HA l3-agent, với bản đang dùng là Rocky thì khi một l3-agent chết nó sẽ không thể phục hồi lại `qrouterXXX` trên một con agent mới.

Ví dụ, tạo một router mới:

	openstack router create router

Kiểm tra các router đc tạo ra cùng lúc đó:

```sh
[root@trang-40-71 ~(openstack)]# neutron l3-agent-list-hosting-router router
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+-------------+----------------+-------+----------+
| id                                   | host        | admin_state_up | alive | ha_state |
+--------------------------------------+-------------+----------------+-------+----------+
| 2d094e7f-5693-4a89-a32e-db7940d40c23 | trang-40-72 | True           | :-)   | standby  |
| a6f87958-1f1f-4ac0-a9f9-66d6e43ff60a | trang-40-73 | True           | :-)   | active   |
+--------------------------------------+-------------+----------------+-------+----------+
```

Tắt thử `neutron-l3-agent` trên host `trang-40-72` đi và kiểm tra lại

```sh
[root@trang-40-71 ~(openstack)]# neutron l3-agent-list-hosting-router router
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+-------------+----------------+-------+----------+
| id                                   | host        | admin_state_up | alive | ha_state |
+--------------------------------------+-------------+----------------+-------+----------+
| 2d094e7f-5693-4a89-a32e-db7940d40c23 | trang-40-72 | True           | xxx   | standby  |
| a6f87958-1f1f-4ac0-a9f9-66d6e43ff60a | trang-40-73 | True           | :-)   | active   |
+--------------------------------------+-------------+----------------+-------+----------+
```

Khi đó một con router `standby` như trên sẽ hiện thị ở trạng thái cho thấy đang bị chết, chứ không hề đổi sang host mới (một host khác được cài l3-agent mà chưa có một namespace của router đó). Sau khi bật lại `l3-agent` bị tắt thì router sẽ hoạt động trở lại.

Nếu router `active` nằm trên một node bị `down` (ví dụ node bị tắt), thì con router đó sẽ chuyển sang trạng thái `standby`, router còn lại sẽ chuyển sang trạng thái `active` (có metadata).

Trong trường hợp node chỉ tắt agent chứ node đó không down, thì router trên node đó nếu đang ở trạng thái `active` thì sẽ chuyển về trạng thái `stanby`, nhưng con router ở trên node còn lại sẽ không chuyển sang trạng thái `active`, như vậy sẽ có hai con router đều ở trạng thái `standby`, thực chất thì router trên node bị tắt agent vẫn hoạt động như một router active (vẫn có metadata).

**Update lại:** Nếu thử tắt một con l3-agent đi, sau đó lên controller xóa service của nó, khởi động lại neutron-server, rồi kiểm tra lại các node chưa router bằng command `neutron l3-agent-list-hosting-router` ta sẽ thấy router sẽ được chuyển sang một con mới con sống và chưa có namespace cho router đó (sao cho đủ số lượng router).


<a name="#ref"></a>
## Tham khảo

[1] https://docs.openstack.org/neutron/pike/admin/deploy-ovs-ha-vrrp.html#deploy-ovs-ha-vrrp

[2] https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/14/html/networking_guide/sec-l3-ha

[3] https://docs.openstack.org/neutron/pike/admin/config-dvr-ha-snat.html

[4] https://docs.openstack.org/neutron/rocky/admin/config-ovsfwdriver.html

[5] https://docs.openstack.org/mitaka/networking-guide/deploy-ovs-ha-vrrp.html#deploy-ovs-ha-vrrp

[6] https://www.openstackfaq.com/openstack-migrate-routers-and-dhcp/